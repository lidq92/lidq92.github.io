<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-169048535-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-169048535-1');
  </script>

  <title>Dingquan Li</title>
  
  <meta name="author" content="Dingquan Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Dingquan Li</name>
              </p>
              <p>
                I am currently an Assistant Researcher at <a href="https://pcl.ac.cn">Peng Cheng Laboratory (PCL)</a>, where I previously did my Postdoc with Prof. Ge Li. I did my PhD at <a href="http://www.math.pku.edu.cn/">School of Mathematical Sciences</a> & <a href="http://bicmr.pku.edu.cn/">BICMR</a> at <a href="http://pku.edu.cn/">Peking University</a>, where I was advised by Prof. <a href="http://www.math.pku.edu.cn/teachers/jiangm/">Ming Jiang</a> and Prof. <a href="http://www.vie.group/ttj/">Tingting Jiang</a>. During this period, I was also a research assistant in the <a href="http://www.vie.group/">VIE</a> group at <a href="https://idm.pku.edu.cn/en//">NERCVT</a> of <a href="http://pku.edu.cn/">Peking University</a>. Before coming to <a href="http://pku.edu.cn/">Peking University</a> in 2015, I did my bachelors at <a href="http://www.nankai.edu.cn/">Nankai University</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:dingquanli@pku.edu.cn">Email</a> &nbsp/&nbsp
                <a href="data/DingquanLi-CV_cn.pdf">CV_cn</a> &nbsp/&nbsp
                <!-- <a href="data/DingquanLi-bio.txt">Biography</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=hdRPwGkAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/lidq92"> Github </a> &nbsp/&nbsp
                <a href="https://www.researchgate.net/profile/Dingquan_Li3"> ResearchGate </a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/dingquan-li-9454407b/"> Linkedin </a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/DingquanLi.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/DingquanLi.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>My main interest lies in image, video, and point cloud processing, especially including:</p>
              <ul>
                <li>Point Cloud Compression</li>
                <li>Remote Sensing Data Compression</li>
                <li>Image/Video Quality Assessment</li>
                <li>Perceptual Optimization</li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<!-- 
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='font_image'><img src='images/font_after.png'></div>
                <img src='images/font_before.png'>
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="TODO">
                <papertitle>A Deep Factorization of Style and Structure in Fonts</papertitle>
              </a>
              <br>
              <a href="http://www.cs.cmu.edu/~asrivats/">Akshay Srivatsan</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://people.eecs.berkeley.edu/~klein/">Dan Klein</a>,
              <a href="http://cseweb.ucsd.edu/~tberg/">Taylor Berg-Kirkpatrick</a>
              <br>
              <em>EMNLP</em>, 2019
              <br>
              <p></p>
              <p>Variational auto-encoders can be used to disentangle a characters style from its content.</p>
            </td>
          </tr> -->
<!-- 
          <tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/loss_after.png'></div>
                <img src='images/loss_before.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }

                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/open?id=1xpZ0fL9h1y9RfcTyPgVkxUrF3VwdkBvq">
                <papertitle>A General and Adaptive Robust Loss Function</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>CVPR</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Award Finalist)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/1701.03077">arxiv</a> /
              <a href="https://drive.google.com/open?id=1HNveL7xSNh6Ss7sxLK8Mw2L1Fc-rRhL4">supplement</a> /
              <a href="https://youtu.be/BmNKbnF69eY">video</a> /
              <a href="https://www.youtube.com/watch?v=4IInDT_S0ow&t=37m22s">talk</a> / 
              <a href="https://drive.google.com/file/d/1GzRYRIfLHvNLT_QwjHoBjHkBbs3Nbf0x/view?usp=sharing">slides</a> / 
              <a href="https://github.com/google-research/google-research/tree/master/robust_loss">tensorflow code</a> /
              <a href="https://github.com/jonbarron/robust_loss_pytorch">pytorch code</a> /
              <a href="data/BarronCVPR2019_reviews.txt">reviews</a> /
              <a href="data/BarronCVPR2019.bib">bibtex</a>
              <p></p>
              <p>A single robust loss function is a superset of many other common robust loss functions, and allows training to automatically adapt the robustness of its own loss.</p>
            </td>
          </tr> -->

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>Selected Publications</heading>
              </td>
            </tr>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2402.11250">
                <papertitle>Hierarchical Prior-based Super Resolution for Point Cloud Geometry Compression</papertitle>
              </a>
              <br>
              <strong>Dingquan Li</strong>, 
              <a href='https://kedema.org/'>Kede Ma</a>, 
              <a href=''>Jing Wang</a>,
              <a href=''>Ge Li</a>
              <br>
              <em>IEEE Transactions on Image Processing (TIP)</em>, 2024. &nbsp <font color="red"><strong>(SCI JCR Q1, IF=10.6; CCF A)</strong></font>
              <br>
              <a href="https://github.com/lidq92/mpeg-pcc-tmc13/tree/hpsr_pcgc">code</a> 
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2011.04263">
                <papertitle>Unified Quality Assessment of In-the-Wild Videos with Mixed Datasets Training</papertitle>
              </a>
              <br>
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>, 
              <a href='http://www.math.pku.edu.cn/teachers/jiangm/'>Ming Jiang</a>
              <br>
              <em>International Journal of Computer Vision (IJCV) Special Issue on Computer Vision in the Wild</em>, 2021. &nbsp <font color="red"><strong>(SCI JCR Q1, IF=5.698; CCF A)</strong></font>
              <br>
              <a href="https://github.com/lidq92/MDTVSFA">code</a> 
              <!-- <a class="btn btn-sm btn-with-count  tooltipped tooltipped-s" aria-label="You must be signed in to star a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:310229560,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/MDTVSFA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="1f7c8e0ec853ca4d7ae471d8b9e80890a0f55021e7e5c312c90cddda7186d474" href="https://github.com/login?return_to=%2Flidq92%2FMDTVSFA">
                <svg class="octicon octicon-star v-align-text-bottom" height="16" viewBox="0 0 16 16" version="1.1" width="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 .25a.75.75 0 01.673.418l1.882 3.815 4.21.612a.75.75 0 01.416 1.279l-3.046 2.97.719 4.192a.75.75 0 01-1.088.791L8 12.347l-3.766 1.98a.75.75 0 01-1.088-.79l.72-4.194L.818 6.374a.75.75 0 01.416-1.28l4.21-.611L7.327.668A.75.75 0 018 .25zm0 2.445L6.615 5.5a.75.75 0 01-.564.41l-3.097.45 2.24 2.184a.75.75 0 01.216.664l-.528 3.084 2.769-1.456a.75.75 0 01.698 0l2.77 1.456-.53-3.084a.75.75 0 01.216-.664l2.24-2.183-3.096-.45a.75.75 0 01-.564-.41L8 2.694v.001z"></path></svg>
              </a>
              <a class="social-count js-social-count" href="https://github.com/lidq92/MDTVSFA/stargazers" aria-label="34 users starred this repository">34
              </a>
              <a class="btn btn-sm btn-with-count tooltipped tooltipped-s" aria-label="You must be signed in to fork a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:310229560,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/MDTVSFA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="eccfab49ea7e30f68c9d246b5fe40e74a4831dce6d6a29aaca2536ce2e091a58" href="https://github.com/login?return_to=%2Flidq92%2FMDTVSFA">
                <svg class="octicon octicon-repo-forked" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M5 3.25a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm0 2.122a2.25 2.25 0 10-1.5 0v.878A2.25 2.25 0 005.75 8.5h1.5v2.128a2.251 2.251 0 101.5 0V8.5h1.5a2.25 2.25 0 002.25-2.25v-.878a2.25 2.25 0 10-1.5 0v.878a.75.75 0 01-.75.75h-4.5A.75.75 0 015 6.25v-.878zm3.75 7.378a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm3-8.75a.75.75 0 100-1.5.75.75 0 000 1.5z"></path></svg>
              </a>
              <a href="https://github.com/lidq92/lidq92/MDTVSFA/network/members" class="social-count" aria-label="11 user forked this repository">11</a>
              /
              <a href="data/LiIJCV2020.bib">bibtex</a>
              <p>A mixed datasets training strategy for training a single unified VQA model with multiple datasets</p> -->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="http://www.vie.group/media/pdf/08489929.pdf">
                <papertitle>Which Has Better Visual Quality: The Clear Blue Sky or a Blurry Animal?</papertitle>
              </a>
              <br>
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>, 
              <a href='https://www.ntu.edu.sg/home/wslin/'>Weisi Lin</a>, 
              <a href='http://www.math.pku.edu.cn/teachers/jiangm/'>Ming Jiang</a>
              <br>
              <em>IEEE Transactions on Multimedia (TMM)</em>, 2019 &nbsp <font color="red"><strong>(SCI JCR Q1, IF=5.452; CCF B)</strong></font>
              <br>
              <a href="http://www.vie.group/media/pdf/PKU-NTU_Workshop_Macau2018-TMM_presentation.pdf">slides</a> / 
              <a href="https://github.com/lidq92/SFA">code</a> 
              <!-- <a class="btn btn-sm btn-with-count  tooltipped tooltipped-s" aria-label="You must be signed in to star a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:119025388,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/SFA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="64dbd292aea623b947e07b7c45d52562a7ced9e01acf39fbdff1a0ec328c74da" href="https://github.com/login?return_to=%2Flidq92%2FSFA">
                <svg height="16" class="octicon octicon-star v-align-text-bottom" vertical_align="text_bottom" viewBox="0 0 16 16" version="1.1" width="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 .25a.75.75 0 01.673.418l1.882 3.815 4.21.612a.75.75 0 01.416 1.279l-3.046 2.97.719 4.192a.75.75 0 01-1.088.791L8 12.347l-3.766 1.98a.75.75 0 01-1.088-.79l.72-4.194L.818 6.374a.75.75 0 01.416-1.28l4.21-.611L7.327.668A.75.75 0 018 .25zm0 2.445L6.615 5.5a.75.75 0 01-.564.41l-3.097.45 2.24 2.184a.75.75 0 01.216.664l-.528 3.084 2.769-1.456a.75.75 0 01.698 0l2.77 1.456-.53-3.084a.75.75 0 01.216-.664l2.24-2.183-3.096-.45a.75.75 0 01-.564-.41L8 2.694v.001z"></path></svg></a> 
              <a class="social-count js-social-count" href="https://github.com/lidq92/SFA/stargazers" aria-label="51 users starred this repository">51</a>
              <a class="btn btn-sm btn-with-count tooltipped tooltipped-s" aria-label="You must be signed in to fork a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:119025388,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/SFA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="f510e148b10d64ff451ad2e95a4b503ebf752ccab702aa1262d778f3d5665b5e" href="https://github.com/login?return_to=%2Flidq92%2FSFA">
                <svg class="octicon octicon-repo-forked" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M5 3.25a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm0 2.122a2.25 2.25 0 10-1.5 0v.878A2.25 2.25 0 005.75 8.5h1.5v2.128a2.251 2.251 0 101.5 0V8.5h1.5a2.25 2.25 0 002.25-2.25v-.878a2.25 2.25 0 10-1.5 0v.878a.75.75 0 01-.75.75h-4.5A.75.75 0 015 6.25v-.878zm3.75 7.378a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm3-8.75a.75.75 0 100-1.5.75.75 0 000 1.5z"></path></svg></a>
              <a href="https://github.com/lidq92/SFA/network/members" class="social-count" aria-label="13 users forked this repository">13</a> /
              <a href="data/LiTMM2019.bib">bibtex</a>
              <p></p>
              <p>Most conventional objective metrics prefer blurry animals (relatively complex visual content) over clear the blue sky (simple content), contradicting with human perception: content-aware features help ...</p> -->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2008.03889">
                <papertitle>Norm-in-Norm Loss with Faster Convergence and Better Performance for Image Quality Assessment</papertitle>
              </a>
              <br>
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>, 
              <a href='http://www.math.pku.edu.cn/teachers/jiangm/'>Ming Jiang</a>
              <br>
              <em>ACM International Conference on Multimedia (MM)</em>, 2020 &nbsp <font color="red"><strong>(Oral, CCF A)</strong></font>
              <br>
              <a href="http://www.vie.group/media/pdf/MM20-fp0612.mp4">video</a> / 
              <a href="http://www.vie.group/media/pdf/MM20-fp0612-one-slide.pdf">poster</a> / 
              <a href="https://github.com/lidq92/LinearityIQA">code</a> 
              <!-- <a class="btn btn-sm btn-with-count  tooltipped tooltipped-s" aria-label="You must be signed in to star a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:284060958,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/LinearityIQA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="82661f29a63200e6079465d3303bb73ac22117ccdb7701103f144fa58b3dd68d" href="https://github.com/login?return_to=%2Flidq92%2FLinearityIQA">
                <svg vertical_align="text_bottom" height="16" class="octicon octicon-star v-align-text-bottom" viewBox="0 0 16 16" version="1.1" width="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 .25a.75.75 0 01.673.418l1.882 3.815 4.21.612a.75.75 0 01.416 1.279l-3.046 2.97.719 4.192a.75.75 0 01-1.088.791L8 12.347l-3.766 1.98a.75.75 0 01-1.088-.79l.72-4.194L.818 6.374a.75.75 0 01.416-1.28l4.21-.611L7.327.668A.75.75 0 018 .25zm0 2.445L6.615 5.5a.75.75 0 01-.564.41l-3.097.45 2.24 2.184a.75.75 0 01.216.664l-.528 3.084 2.769-1.456a.75.75 0 01.698 0l2.77 1.456-.53-3.084a.75.75 0 01.216-.664l2.24-2.183-3.096-.45a.75.75 0 01-.564-.41L8 2.694v.001z"></path></svg>
              </a>
              <a class="social-count js-social-count" href="https://github.com/lidq92/LinearityIQA/stargazers" aria-label="38 users starred this repository">38</a>
              <a class="btn btn-sm btn-with-count tooltipped tooltipped-s" aria-label="You must be signed in to fork a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:284060958,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/LinearityIQA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="c5f532420a3db3c7f552dc0f781442c75456f7379abf9192a6e067e4f5c6eb38" href="https://github.com/login?return_to=%2Flidq92%2FLinearityIQA">
                <svg class="octicon octicon-repo-forked" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M5 3.25a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm0 2.122a2.25 2.25 0 10-1.5 0v.878A2.25 2.25 0 005.75 8.5h1.5v2.128a2.251 2.251 0 101.5 0V8.5h1.5a2.25 2.25 0 002.25-2.25v-.878a2.25 2.25 0 10-1.5 0v.878a.75.75 0 01-.75.75h-4.5A.75.75 0 015 6.25v-.878zm3.75 7.378a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm3-8.75a.75.75 0 100-1.5.75.75 0 000 1.5z"></path></svg>
              </a>
              <a href="https://github.com/lidq92/LinearityIQA/network/members" class="social-count" aria-label="10 users forked this repository">10</a>
              /
              <a href="data/LiACMMM2020.bib">bibtex</a>
              <p></p>
              <p>Normalization-embedded loss is conducive to the faster convergence and better performance of the IQA model.</p> -->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1908.00375">
                <papertitle>Quality Assessment of In-the-Wild Videos</papertitle>
              </a>
              <br>
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>, 
              <a href='http://www.math.pku.edu.cn/teachers/jiangm/'>Ming Jiang</a>
              <br>
              <em>ACM International Conference on Multimedia (MM)</em>, 2019 &nbsp <font color="red"><strong>(Oral, CCF A)</strong></font>
              <br>
              <a href="http://www.vie.group/media/pdf/P5B-01_presentation_with_videos.pptx">slides</a> / 
              <a href="http://www.vie.group/media/pdf/P5B-01.pdf">poster</a> / 
              <a href="https://github.com/lidq92/VSFA">code</a> 
              <!-- <a class="btn btn-sm btn-with-count  tooltipped tooltipped-s" aria-label="You must be signed in to star a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:195149316,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/VSFA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="dc4afc52face7c58e577d0aeafea161ddbbf4de0008fc9ff1784c4bafefabe44" href="https://github.com/login?return_to=%2Flidq92%2FVSFA"><svg height="16" class="octicon octicon-star v-align-text-bottom" vertical_align="text_bottom" viewBox="0 0 16 16" version="1.1" width="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 .25a.75.75 0 01.673.418l1.882 3.815 4.21.612a.75.75 0 01.416 1.279l-3.046 2.97.719 4.192a.75.75 0 01-1.088.791L8 12.347l-3.766 1.98a.75.75 0 01-1.088-.79l.72-4.194L.818 6.374a.75.75 0 01.416-1.28l4.21-.611L7.327.668A.75.75 0 018 .25zm0 2.445L6.615 5.5a.75.75 0 01-.564.41l-3.097.45 2.24 2.184a.75.75 0 01.216.664l-.528 3.084 2.769-1.456a.75.75 0 01.698 0l2.77 1.456-.53-3.084a.75.75 0 01.216-.664l2.24-2.183-3.096-.45a.75.75 0 01-.564-.41L8 2.694v.001z"></path></svg></a>
              <a class="social-count js-social-count" href="https://github.com/lidq92/VSFA/stargazers" aria-label="112 users starred this repository">112</a> 
              <a class="btn btn-sm btn-with-count tooltipped tooltipped-s" aria-label="You must be signed in to fork a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:195149316,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/VSFA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="04588d4b5f022392ef24a2c5520a75ed086ed2f4a9997e13901732d35a553f0c" href="https://github.com/login?return_to=%2Flidq92%2FVSFA">
                <svg class="octicon octicon-repo-forked" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M5 3.25a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm0 2.122a2.25 2.25 0 10-1.5 0v.878A2.25 2.25 0 005.75 8.5h1.5v2.128a2.251 2.251 0 101.5 0V8.5h1.5a2.25 2.25 0 002.25-2.25v-.878a2.25 2.25 0 10-1.5 0v.878a.75.75 0 01-.75.75h-4.5A.75.75 0 015 6.25v-.878zm3.75 7.378a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm3-8.75a.75.75 0 100-1.5.75.75 0 000 1.5z"></path></svg></a>
              <a href="https://github.com/lidq92/VSFA/network/members" class="social-count" aria-label="29 users forked this repository">29</a> /
              <a href="data/LiACMMM2019.bib">bibtex</a>
              <p></p>
              <p>Content dependency and temporal-memory effects of HVS are considered in the design of NR-VQA models.</p> -->
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1810.08169">
                <papertitle>Exploiting High-Level Semantics for No-Reference Image Quality Assessment of Realistic Blur Images</papertitle>
              </a>
              <br>
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>, 
              <a href='http://www.math.pku.edu.cn/teachers/jiangm/'>Ming Jiang</a>
              <br>
              <em>ACM International Conference on Multimedia (MM)</em>, 2017 &nbsp <font color="red"><strong>(CCF A)</strong></font>
              <br>
              <a href="http://www.vie.group/media/pdf/frp303-fast_forward.pptx">slides</a> / 
              <a href="http://www.vie.group/media/pdf/acmmm17_poster-updated_3BofFhr.pdf">poster</a> / 
              <a href="https://github.com/lidq92/SFA">code</a> 
              <!-- <a class="btn btn-sm btn-with-count  tooltipped tooltipped-s" aria-label="You must be signed in to star a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:119025388,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/SFA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="64dbd292aea623b947e07b7c45d52562a7ced9e01acf39fbdff1a0ec328c74da" href="https://github.com/login?return_to=%2Flidq92%2FSFA">
                <svg height="16" class="octicon octicon-star v-align-text-bottom" vertical_align="text_bottom" viewBox="0 0 16 16" version="1.1" width="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 .25a.75.75 0 01.673.418l1.882 3.815 4.21.612a.75.75 0 01.416 1.279l-3.046 2.97.719 4.192a.75.75 0 01-1.088.791L8 12.347l-3.766 1.98a.75.75 0 01-1.088-.79l.72-4.194L.818 6.374a.75.75 0 01.416-1.28l4.21-.611L7.327.668A.75.75 0 018 .25zm0 2.445L6.615 5.5a.75.75 0 01-.564.41l-3.097.45 2.24 2.184a.75.75 0 01.216.664l-.528 3.084 2.769-1.456a.75.75 0 01.698 0l2.77 1.456-.53-3.084a.75.75 0 01.216-.664l2.24-2.183-3.096-.45a.75.75 0 01-.564-.41L8 2.694v.001z"></path></svg></a> 
              <a class="social-count js-social-count" href="https://github.com/lidq92/SFA/stargazers" aria-label="51 users starred this repository">51</a>
              <a class="btn btn-sm btn-with-count tooltipped tooltipped-s" aria-label="You must be signed in to fork a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:119025388,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/SFA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="f510e148b10d64ff451ad2e95a4b503ebf752ccab702aa1262d778f3d5665b5e" href="https://github.com/login?return_to=%2Flidq92%2FSFA">
                <svg class="octicon octicon-repo-forked" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M5 3.25a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm0 2.122a2.25 2.25 0 10-1.5 0v.878A2.25 2.25 0 005.75 8.5h1.5v2.128a2.251 2.251 0 101.5 0V8.5h1.5a2.25 2.25 0 002.25-2.25v-.878a2.25 2.25 0 10-1.5 0v.878a.75.75 0 01-.75.75h-4.5A.75.75 0 015 6.25v-.878zm3.75 7.378a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm3-8.75a.75.75 0 100-1.5.75.75 0 000 1.5z"></path></svg></a>
              <a href="https://github.com/lidq92/SFA/network/members" class="social-count" aria-label="13 users forked this repository">13</a> /
              <a href="data/LiACMMM2017.bib">bibtex</a>
              <p></p>
              <p>High-level semantic features extracted from pre-trained image classification models help NR-IQA.</p> -->
            </td>
          </tr>

          <!-- <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="http://www.vie.group/media/pdf/Blur-Specific_NR-IQA_A_Classification_and_Review_of_Representative_Methods.pdf">
                <papertitle>Blur-Specific No-Reference Image Quality Assessment: A Classification and Review of Representative Methods</papertitle>
              </a>
              <br>
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>
              <br>
              <em>Proceedings of the International Conference on Sensing and Imaging</em>, 2019 &nbsp <font color="red"><strong>(Invited Chapter)</strong></font>
              <br>
              <a href="data/LiICSI2019.bib">bibtex</a>
              <p></p>
            </td>
          </tr> -->

          <!-- <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="http://www.vie.group/media/pdf/Li_et_al.-2019ZTE_Communications-Recent_Advances_and_Challenges_in_Video_Quality_Assessment.pdf">
                <papertitle>Recent Advances and Challenges in Video Quality Assessment</papertitle>
              </a>
              <br>
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>, 
              <a href='http://www.math.pku.edu.cn/teachers/jiangm/'>Ming Jiang</a>
              <br>
              <em>ZTE Communications</em>, 2019 &nbsp <font color="red"><strong>(Invited Paper)</strong></font>
              <br>
              <a href="data/LiZTE2019.bib">bibtex</a>
              <p></p>
            </td>
          </tr> -->

          <!-- <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1810.08339">
                <papertitle>Quality Assessment for Tone-Mapped HDR Images Using Multi-Scale and Multi-Layer Information</papertitle>
              </a>
              <br>
              <a href="">Qin He</a>, 
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>, 
              <a href='http://www.math.pku.edu.cn/teachers/jiangm/'>Ming Jiang</a>
              <br>
              <em>IEEE International Conference on Multimedia & Expo Workshop (ICMEw)</em>, 2018 &nbsp <font color="red"><strong></strong></font>
              <br>
              <a href="https://github.com/lidq92/msmlTMIQA">code</a> /
              <a href="data/LiZTE2019.bib">bibtex</a>
              <p></p>
            </td>
          </tr> -->

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Academic Services</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td>
              Reviewer for TPAMI, TIP, TMM, TCSVT, IJCV, CVPR, ICCV, ECCV, ACM MM, NeurIPS, ICLR, ICML, AAAI, IJCAI, etc.
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                <a href="https://jonbarron.info">Template credit to Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
